{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**PC Recommender**\n"
      ],
      "metadata": {
        "id": "pGg00693wYSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-4XeLbQbuLGK"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"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\""
      ],
      "metadata": {
        "id": "Gay0B6Rhuaz2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "url = \"https://api.groq.com/openai/v1/chat/completions\""
      ],
      "metadata": {
        "id": "g1ZINWenusom"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "  {\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"You're a PC Recommender. Recommend between two specifications. (Single line)\"\n",
        "  }\n",
        "]\n",
        "while True:\n",
        "  prompt = input(\"Enter the prompt\")\n",
        "  messages.append(\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": prompt\n",
        "    }\n",
        "  )\n",
        "  data = {\n",
        "    \"messages\": messages,\n",
        "    \"model\": \"llama3-8b-8192\",\n",
        "    \"temperature\": 0\n",
        "  }\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "  }\n",
        "\n",
        "  res = requests.post(\n",
        "      url, data=json.dumps(data), headers=headers\n",
        "  )\n",
        "  res = res.json()\n",
        "  data = res[\"choices\"][0][\"message\"][\"content\"]\n",
        "  messages.append(\n",
        "      {\n",
        "          \"role\": \"assistant\",\n",
        "          \"content\": data\n",
        "      }\n",
        "  )\n",
        "  print(data)\n",
        "  print(\"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "prBi5VKBvHBV",
        "outputId": "0dafbdae-5f39-4bb4-b5b2-f9aa73877bf9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the prompt Intel i5 11th gen or intel i5 12th gen\n",
            "I'd recommend the Intel i5 12th gen over the 11th gen, as it offers improved performance, power efficiency, and features like PCIe 4.0 and DDR5 support, making it a better value for future-proofing and gaming.\n",
            "\n",
            "\n",
            "\n",
            "Enter the prompt Lenovo Ideapad Gaming 3 GTX 1650 or Acer Nitro 5 GTX 1650\n",
            "I'd recommend the Acer Nitro 5 GTX 1650 over the Lenovo Ideapad Gaming 3 GTX 1650, as the Nitro 5 has a more powerful cooling system, a better display with higher refresh rate and resolution options, and a more customizable design with RGB lighting, making it a better overall gaming laptop.\n",
            "\n",
            "\n",
            "\n",
            "Enter the prompt Ryzen 5 or Ryzen 6\n",
            "I'd recommend the Ryzen 6 over the Ryzen 5, as it offers 2-3 cores and threads more, which can provide a significant boost in multitasking, content creation, and gaming performance, making it a better value for those who need more processing power.\n",
            "\n",
            "\n",
            "\n",
            "Enter the promptWhat is specifications to run LLMs?\n",
            "Large Language Models (LLMs) typically require powerful hardware to run efficiently. Here are some general specifications that can help you run LLMs:\n",
            "\n",
            "1. CPU: At least 8-10 cores, preferably with a high clock speed (e.g., Intel Core i9 or AMD Ryzen 9).\n",
            "2. GPU: A high-end graphics card with a minimum of 8 GB of VRAM, such as NVIDIA GeForce RTX 3080 or AMD Radeon RX 6800 XT.\n",
            "3. RAM: 32-64 GB of DDR4 or DDR5 RAM, with a speed of at least 3200 MHz.\n",
            "4. Storage: A fast NVMe SSD with a capacity of at least 1 TB, such as an M.2 SSD with a read/write speed of 5000 MB/s.\n",
            "5. Operating System: A 64-bit version of Windows 10 or Linux (e.g., Ubuntu).\n",
            "6. Software: A compatible deep learning framework such as TensorFlow, PyTorch, or Hugging Face's Transformers.\n",
            "\n",
            "Keep in mind that these are general guidelines, and the specific requirements may vary depending on the LLM model, its size, and the tasks you want to perform.\n",
            "\n",
            "\n",
            "\n",
            "Enter the prompt Under 1 lakh\n",
            "Under 1 lakh, here are some specifications that can help you run LLMs:\n",
            "\n",
            "1. CPU: Intel Core i5 or AMD Ryzen 5 with 6-8 cores, clocked at 3.5-4.5 GHz.\n",
            "2. GPU: NVIDIA GeForce GTX 1660 Super or AMD Radeon RX 5600 XT with 6 GB of VRAM.\n",
            "3. RAM: 16-24 GB of DDR4 RAM, clocked at 3200 MHz.\n",
            "4. Storage: 512 GB or 1 TB NVMe SSD with a read/write speed of 3500 MB/s.\n",
            "5. Operating System: 64-bit version of Windows 10 or Linux (e.g., Ubuntu).\n",
            "\n",
            "Some examples of laptops that fit these specifications and are available under 1 lakh:\n",
            "\n",
            "* Acer Aspire 5 with Intel Core i5-1135G7, NVIDIA GeForce GTX 1660 Ti, 16 GB RAM, and 512 GB SSD (around 80,000 INR)\n",
            "* Lenovo Legion 5 with AMD Ryzen 5 5600H, NVIDIA GeForce GTX 1660 Ti, 16 GB RAM, and 512 GB SSD (around 90,000 INR)\n",
            "* Dell G3 15 with Intel Core i5-1135G7, NVIDIA GeForce GTX 1660 Ti, 16 GB RAM, and 512 GB SSD (around 95,000 INR)\n",
            "\n",
            "Please note that these are just examples, and you may need to adjust your expectations based on your specific needs and budget.\n",
            "\n",
            "\n",
            "\n",
            "Enter the promptWhich is best for video analytics?\n",
            "For video analytics, I'd recommend the following specifications:\n",
            "\n",
            "1. CPU: Intel Core i7 or AMD Ryzen 7 with 8-10 cores, clocked at 3.5-4.5 GHz.\n",
            "2. GPU: NVIDIA GeForce RTX 3060 or AMD Radeon RX 6700 XT with 8 GB of VRAM.\n",
            "3. RAM: 32-64 GB of DDR4 or DDR5 RAM, clocked at 3200 MHz.\n",
            "4. Storage: 1 TB or 2 TB NVMe SSD with a read/write speed of 5000 MB/s.\n",
            "5. Operating System: 64-bit version of Windows 10 or Linux (e.g., Ubuntu).\n",
            "\n",
            "These specifications will provide the necessary processing power and memory to handle video analytics tasks such as:\n",
            "\n",
            "* Video encoding and decoding\n",
            "* Object detection and tracking\n",
            "* Facial recognition\n",
            "* Sentiment analysis\n",
            "* Motion detection\n",
            "\n",
            "Some examples of laptops that fit these specifications and are available under 1 lakh:\n",
            "\n",
            "* MSI PS65 with Intel Core i7-11800H, NVIDIA GeForce RTX 3060, 32 GB RAM, and 1 TB SSD (around 1.2 lakhs)\n",
            "* Dell XPS 15 with Intel Core i7-11800H, NVIDIA GeForce RTX 3060, 32 GB RAM, and 1 TB SSD (around 1.3 lakhs)\n",
            "* HP ZBook 15 with Intel Core i7-11800H, NVIDIA GeForce RTX 3060, 32 GB RAM, and 1 TB SSD (around 1.4 lakhs)\n",
            "\n",
            "Please note that these are just examples, and you may need to adjust your expectations based on your specific needs and budget.\n",
            "\n",
            "\n",
            "\n",
            "Enter the promptExit\n",
            "It was nice chatting with you! If you have any more questions or need further recommendations, feel free to come back anytime. Have a great day!\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3ce77112c3db>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the prompt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   messages.append(\n\u001b[1;32m     10\u001b[0m     {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y52g1tjiwI-N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}